{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation using nonlinear-monotone data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how to use nonlinear-monotone data for parameter optimization in pyPESTO.\n",
    "\n",
    "We define a dataset of nonlinear-monotone data as $\\{\\widetilde{z}_k\\}_{k=1}^N$ such that there exists a monotone (often unknown exactly) function $f$ which defines the relationship of the data and the model output:\n",
    "$$\\widetilde{z}_k = f(y_k(t_k, \\theta), \\theta) + \\varepsilon_k, \\quad k = 1, ..., N$$\n",
    "Where:\n",
    "- $\\{y_k\\}_{k=1}^N$ is the model output at timepoints $\\{t_k\\}_{k=1}^N$, \n",
    "- $\\{\\varepsilon_k\\}_{k=1}^N$ is the measurement noise (usually normally distributed), \n",
    "- and $\\theta$ is the vector of model (unknown) dynamical parameters.\n",
    "\n",
    "This type of data can, for instance, be a result of FÃ¶rster resonance energy transfer (FRET) measurements or saturated Western blots. \n",
    "\n",
    "In pyPESTO, we have implemented an alogorithm which constructs and optimizes a spline approximation $s(y, \\xi)$ (piecewise linear function to be exact) of the nonlinear-monotone function $f(y_k(t_k, \\theta), \\theta)$. All model parameters are estimated hierarchically:\n",
    "- The dynamical parameters $\\theta$ are optimized in the outer hiearchical loop,\n",
    "- The spline parameters $\\xi$ are optimized in the inner loop for each iteration of the outer one.\n",
    "\n",
    "In the following we will demonstrate how to use the spline approximation approach for integration of nonlinear-monotone data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem specification & importing model from the petab_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import petab\n",
    "\n",
    "import pypesto\n",
    "import pypesto.logging\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "from pypesto.C import LIN, InnerParameterType\n",
    "from pypesto.hierarchical.spline_approximation import (\n",
    "    SplineInnerProblem,\n",
    "    SplineInnerSolver,\n",
    ")\n",
    "from pypesto.hierarchical.spline_approximation.parameter import (\n",
    "    SplineInnerParameter,\n",
    ")\n",
    "from pypesto.hierarchical.spline_approximation.visualize import (\n",
    "    plot_splines_from_inner_result,\n",
    "    plot_splines_from_pypesto_result,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify usage of nonlinear-monotone data, only `nonlinear_monotone=True` has to be passed to the constructor of the `PetabImporter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_folder = './example_nonlinear_monotone/'\n",
    "yaml_file = 'example_nonlinear_monotone.yaml'\n",
    "\n",
    "petab_problem = petab.Problem.from_yaml(petab_folder + yaml_file)\n",
    "\n",
    "# To allow for optimization with nonlinear_monotone measurements,\n",
    "# set nonlinear_monotone=True, when constructing the importer\n",
    "importer = pypesto.petab.PetabImporter(petab_problem, nonlinear_monotone=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The petab_problem has to be specified in the usual PEtab formulation. The nonlinear-monotone measurements have to be specified in the `measurement.tsv` file by adding  `nonlinear_monotone` in the new `measurementType` column and determining the `measurementGroup`, where group specifies that the measurements come from the same nonlinear monotone function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import option_context\n",
    "\n",
    "with option_context('display.max_colwidth', 400):\n",
    "    display(petab_problem.measurement_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the objective and pypesto problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different options can be used for the spline approximations:\n",
    "- `spline_ratio`: float value, determines the number of spline knots as `n_spline_pars` = `spline_ratio` * `n_datapoints`  \n",
    "- `use_minimal_difference` : `True` / `False`\n",
    "\n",
    "The `use_minimal_difference` option determines whether a minimal difference between the spline heights will be constrained. For most models, enabling this option will increase convergence by increasing error of incorrect ordering. Nevertheless, the option has to be used with caution, as it will reduce the spline's capability of approximating functions with flat regions well. This we will show in this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we construct the `objective`, it will construct all objects of the optimal scaling inner optimization:\n",
    "- `SplineInnerSolver`\n",
    "- `SplineAmiciCalculator`\n",
    "- `SplineInnerProblem`\n",
    "\n",
    "Specifically, the `SplineInnerSolver` and `SplineInnerProblem` will be constructed with default settings of \n",
    "- `spline_ratio` = 1/2\n",
    "- `use_minimal_difference` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = importer.create_objective()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give non-default options to the `OptimalScalingInnerSolver` and `OptimalScalingProblem`, one can pass them as arguments when constructing the `objective`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = importer.create_objective(\n",
    "    inner_solver_options={\n",
    "        \"spline_ratio\": 1 / 2,\n",
    "        \"use_minimal_difference\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can even pass them to the importer constructor `pypesto.petab.PetabImporter()`.\n",
    "\n",
    "If changing the `spline_ratio` setting, one has to create the objective object again, as this requires a constuction of the new `SplineInnerProblem` object with the requested amount of inner parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's construct the pyPESTO problem and optimizer. We're going to use a gradient-based optimizer for a faster optimization, but gradient-free optimizers can be used in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = importer.create_problem(objective)\n",
    "\n",
    "engine = pypesto.engine.SingleCoreEngine()\n",
    "\n",
    "optimizer = optimize.ScipyOptimizer(\n",
    "    method=\"L-BFGS-B\",\n",
    "    options={\"disp\": None, \"ftol\": 2.220446049250313e-09, \"gtol\": 1e-5},\n",
    ")\n",
    "n_starts = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running optimization using spline approximation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running optimization is as simple as running usual pyPESTO miminization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(n_starts)\n",
    "\n",
    "result = optimize.minimize(\n",
    "    problem, n_starts=n_starts, optimizer=optimizer, engine=engine\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model optimization has good convergence with a plateu at the optimal point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.visualize import parameters, waterfall\n",
    "\n",
    "waterfall([result], size=(10, 3))\n",
    "plt.show()\n",
    "parameters([result], size=(10, 3))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the optimized spline of the best start using the `plot_from_pypesto_result` visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_splines_from_pypesto_result(result)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution when enabling minimal difference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate that minimal difference sometimes has a negative effect we will apply it to a very simple synthetic \"model\" -- simulation of the exponential function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = np.linspace(0, 10, 11)\n",
    "function = np.exp\n",
    "\n",
    "simulation = timepoints\n",
    "sigma = np.full(len(timepoints), 1)\n",
    "\n",
    "# Create synthetic data as the exponential function of timepoints\n",
    "data = function(timepoints)\n",
    "\n",
    "spline_ratio = 1 / 2\n",
    "n_spline_pars = int(np.ceil(spline_ratio * len(timepoints)))\n",
    "\n",
    "\n",
    "par_type = 'spline'\n",
    "mask = [np.full(len(simulation), True)]\n",
    "\n",
    "inner_parameters = [\n",
    "    SplineInnerParameter(\n",
    "        inner_parameter_id=f'{par_type}_{1}_{par_index+1}',\n",
    "        inner_parameter_type=InnerParameterType.SPLINE,\n",
    "        scale=LIN,\n",
    "        lb=-np.inf,\n",
    "        ub=np.inf,\n",
    "        ixs=mask,\n",
    "        index=par_index + 1,\n",
    "        group=1,\n",
    "    )\n",
    "    for par_index in range(n_spline_pars)\n",
    "]\n",
    "\n",
    "inner_problem = SplineInnerProblem(\n",
    "    xs=inner_parameters, data=[data], spline_ratio=spline_ratio\n",
    ")\n",
    "\n",
    "options = {\n",
    "    'minimal_diff_on': {\n",
    "        'spline_ratio': 1 / 2,\n",
    "        'use_minimal_difference': True,\n",
    "    },\n",
    "    'minimal_diff_off': {\n",
    "        'spline_ratio': 1 / 2,\n",
    "        'use_minimal_difference': False,\n",
    "    },\n",
    "}\n",
    "inner_solvers = {}\n",
    "results = {}\n",
    "\n",
    "for minimal_diff, option in options.items():\n",
    "    inner_solvers[minimal_diff] = SplineInnerSolver(\n",
    "        options=option,\n",
    "    )\n",
    "\n",
    "    # Solve the inner problem to obtain the optimal spline\n",
    "    results[minimal_diff] = inner_solvers[minimal_diff].solve(\n",
    "        problem=inner_problem,\n",
    "        sim=[simulation],\n",
    "        sigma=[sigma],\n",
    "    )\n",
    "\n",
    "    plot_splines_from_inner_result(inner_problem, results[minimal_diff])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized spline for the case with enabled minimal difference is performing much worse. This is due to the relative flatness of the data with respect to the true model output.\n",
    "\n",
    "The minimal difference is determined as $$\\text{min\\_diff} = \\frac{\\text{measurement\\_range}}{2\\cdot \\text{n\\_inner\\_pars}}$$ \n",
    "so for nonlinear-monotone functions which are relatively flat on some intervals, it is best to keep the minimal difference disabled.\n",
    "\n",
    "As the true output (e.g. observable simulation of the model with true parameters) is mostly a-priori not known, it's hard to know whether the minimal difference is going to have a bad or good effect on the optimization. So a good heuristic is to run both and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4f64b1cfeae9987d9a74471fe6faf49d769577c41c664ee1b5af662a144b184"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
